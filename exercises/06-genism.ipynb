{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Genism NLP Library\n",
    "* Popular open-source NLP library\n",
    "* Uses top academic models to perform complex tasks like\n",
    "    * building document or word vectors\n",
    "    * Performing topic identification and document comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 0,\n",
       " 'a': 1,\n",
       " 'about': 2,\n",
       " 'aliens': 3,\n",
       " 'and': 4,\n",
       " 'is': 5,\n",
       " 'movie': 6,\n",
       " 'spaceship': 7,\n",
       " 'the': 8,\n",
       " '!': 9,\n",
       " 'i': 10,\n",
       " 'liked': 11,\n",
       " 'really': 12,\n",
       " ',': 13,\n",
       " 'action': 14,\n",
       " 'awesome': 15,\n",
       " 'boring': 16,\n",
       " 'but': 17,\n",
       " 'characters.space': 18,\n",
       " 'cool': 19,\n",
       " 'films': 20,\n",
       " 'movie.more': 21,\n",
       " 'please': 22,\n",
       " 'scenes': 23,\n",
       " 'space': 24}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "my_documents = ['The movie is about a spaceship and aliens.',\n",
    "                'I really liked the movie!',\n",
    "                'Awesome action scenes, but boring characters.'\n",
    "                'Space is cool! I liked the movie.'\n",
    "                'More space films, please!',]\n",
    "\n",
    "tokenized_docs = [word_tokenize(doc.lower())\n",
    "                for doc in my_documents]\n",
    "\n",
    "dictionary = Dictionary(tokenized_docs)\n",
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)],\n",
       " [(6, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)],\n",
       " [(5, 1),\n",
       "  (8, 1),\n",
       "  (9, 2),\n",
       "  (10, 1),\n",
       "  (11, 1),\n",
       "  (13, 2),\n",
       "  (14, 1),\n",
       "  (15, 1),\n",
       "  (16, 1),\n",
       "  (17, 1),\n",
       "  (18, 1),\n",
       "  (19, 1),\n",
       "  (20, 1),\n",
       "  (21, 1),\n",
       "  (22, 1),\n",
       "  (23, 1),\n",
       "  (24, 1)]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Token ID and Number of Occurences\n",
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Import Dictionary\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "file = open(\"../datasets/news/articles.txt\", \"r\")\n",
    "articles = file.read()\n",
    "file.close()\n",
    "\n",
    "articles = ['The movie is about a spaceship and aliens.',\n",
    "                'I really liked the movie!',\n",
    "                'Awesome action scenes, but boring characters.'\n",
    "                'Space is cool! I liked the movie.'\n",
    "                'More space films, please!',]\n",
    "\n",
    "tokenized_articles = [word_tokenize(a.lower())\n",
    "                for a in articles]\n",
    "\n",
    "# Create a Dictionary from the articles: dictionary\n",
    "dictionary = Dictionary(tokenized_articles)\n",
    "\n",
    "# Select the id for \"computer\": computer_id\n",
    "computer_id = dictionary.token2id.get(\"computer\")\n",
    "\n",
    "# Use computer_id with the dictionary to print the word\n",
    "print(dictionary.get(computer_id))\n",
    "\n",
    "# Create a MmCorpus: corpus\n",
    "#corpus = [dictionary.doc2bow(tokenized_articles) for article in tokenized_articles]\n",
    "\n",
    "# Print the first 10 word ids with their frequency counts from the fifth document\n",
    "#print(corpus[4][:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
